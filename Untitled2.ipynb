{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "816588cd-64a9-4ead-a2c8-063f6709a4fc",
   "metadata": {},
   "outputs": [
    {
     "ename": "SyntaxError",
     "evalue": "invalid decimal literal (1085720521.py, line 29)",
     "output_type": "error",
     "traceback": [
      "  \u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[4]\u001b[39m\u001b[32m, line 29\u001b[39m\n\u001b[31m    \u001b[39m\u001b[31mdef descent(phi, gradient, x0, gamma=0.15, kmax=200, tol=1e‑8):\u001b[39m\n                                                             ^\n\u001b[31mSyntaxError\u001b[39m\u001b[31m:\u001b[39m invalid decimal literal\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from scipy import optimize\n",
    "\n",
    "# --- Models ---\n",
    "def breit_wigner(e, e_center, gamma, strength):\n",
    "    denom = ((e - e_center)**2) + ((gamma**2)/4.0)\n",
    "    return strength / denom\n",
    "\n",
    "def gaussian(x, mu, sigma, amplitude):\n",
    "    return amplitude * np.exp( - (x - mu)**2 / (2.0 * sigma**2) )\n",
    "\n",
    "# --- Cost / chi‑squared function ---\n",
    "def chi_squared(model_func, param_vec, x_data, y_data, sigma_vals):\n",
    "    y_model = model_func(x_data, *param_vec)\n",
    "    return np.sum( ((y_data - y_model)/sigma_vals)**2 )\n",
    "\n",
    "# --- Gradient & Descent Implementation (your version) ---\n",
    "def gradient(phi, xs, h=0.000001):\n",
    "    n = xs.size\n",
    "    grad = np.zeros_like(xs)\n",
    "    phi0 = phi(xs)\n",
    "    for i in range(n):\n",
    "        xs_h = xs.copy()\n",
    "        xs_h[i] += h\n",
    "        grad[i] = (phi(xs_h) - phi0) / h\n",
    "    return grad\n",
    "\n",
    "def descent(phi, gradient, x0, gamma=0.15, kmax=200, tol=0.00000001):\n",
    "    xs = x0.copy()\n",
    "    history = []\n",
    "    for k in range(1, kmax+1):\n",
    "        grad = gradient(phi, xs)\n",
    "        xnew = xs - gamma * grad\n",
    "        err = np.linalg.norm(xnew - xs)\n",
    "        val = phi(xnew)\n",
    "        history.append((k, xnew.copy(), err, val))\n",
    "        # print(k, xnew, err, val)\n",
    "        if err < tol:\n",
    "            break\n",
    "        xs = xnew\n",
    "    else:\n",
    "        xnew = None\n",
    "    return xnew, history\n",
    "\n",
    "# --- Generate synthetic data ---\n",
    "np.random.seed(12345)\n",
    "# data for Breit‑Wigner\n",
    "true_bw = [5.0, 1.0, 10.0]\n",
    "x_bw = np.linspace(0, 10, 200)\n",
    "y_bw_true = breit_wigner(x_bw, *true_bw)\n",
    "noise_bw = np.random.normal(0, 0.5, size=x_bw.size)\n",
    "y_bw = y_bw_true + noise_bw\n",
    "sigma_bw = np.ones_like(x_bw) * 0.5\n",
    "\n",
    "# data for Gaussian\n",
    "true_gauss = [5.0, 1.0, 10.0]\n",
    "x_gauss = np.linspace(0, 10, 200)\n",
    "y_gauss_true = gaussian(x_gauss, *true_gauss)\n",
    "noise_gauss = np.random.normal(0, 0.5, size=x_gauss.size)\n",
    "y_gauss = y_gauss_true + noise_gauss\n",
    "sigma_gauss = np.ones_like(x_gauss) * 0.5\n",
    "\n",
    "# --- Wrapper functions to use for descent / minimize (param‑vector only) ---\n",
    "def make_phi_model(model_func, x_data, y_data, sigma_vals):\n",
    "    def phi(xs):\n",
    "        return chi_squared(model_func, xs, x_data, y_data, sigma_vals)\n",
    "    return phi\n",
    "\n",
    "# --- Fitting & Comparison Function ---\n",
    "def fit_and_compare(model_name, model_func, x_data, y_data, sigma_vals, initial_guess):\n",
    "    print(f\"\\n=== Model: {model_name} ===\")\n",
    "    # 1) SciPy curve_fit\n",
    "    popt, pcov = optimize.curve_fit(model_func, x_data, y_data,\n",
    "                                     p0=initial_guess, sigma=sigma_vals, absolute_sigma=True)\n",
    "    chi_cf = chi_squared(model_func, popt, x_data, y_data, sigma_vals)\n",
    "    print(\"curve_fit result:\", popt, \"chi² =\", chi_cf)\n",
    "    \n",
    "    # 2) Gradient descent (your implementation)\n",
    "    phi = make_phi_model(model_func, x_data, y_data, sigma_vals)\n",
    "    x0 = np.array(initial_guess, dtype=float)\n",
    "    xopt_gd, hist = descent(phi, gradient, x0, gamma=0.1, kmax=5000, tol=1e‑8)\n",
    "    chi_gd = phi(xopt_gd)\n",
    "    print(\"gradient descent result:\", xopt_gd, \"chi² =\", chi_gd, \"iterations =\", len(hist))\n",
    "    \n",
    "    # 3) optimize.minimize with method 'BFGS'\n",
    "    res_bfgs = optimize.minimize(lambda v: chi_squared(model_func, v, x_data, y_data, sigma_vals),\n",
    "                                 initial_guess, method='BFGS', options={'disp': False})\n",
    "    print(\"minimize (BFGS) result:\", res_bfgs.x, \"chi² =\", res_bfgs.fun,\n",
    "          \"nit =\", res_bfgs.nit, \"nfev =\", res_bfgs.nfev)\n",
    "    \n",
    "    # 4) optimize.minimize with method 'Nelder‑Mead'\n",
    "    res_nm = optimize.minimize(lambda v: chi_squared(model_func, v, x_data, y_data, sigma_vals),\n",
    "                               initial_guess, method='Nelder‑Mead', options={'disp': False})\n",
    "    print(\"minimize (Nelder‑Mead) result:\", res_nm.x, \"chi² =\", res_nm.fun,\n",
    "          \"nit =\", res_nm.nit, \"nfev =\", res_nm.nfev)\n",
    "    \n",
    "    # --- Plot results ---\n",
    "    plt.figure(figsize=(6,4))\n",
    "    plt.errorbar(x_data, y_data, yerr=sigma_vals, fmt='.', label='data', alpha=0.5)\n",
    "    xs_fine = np.linspace(min(x_data), max(x_data), 400)\n",
    "    plt.plot(xs_fine, model_func(xs_fine, *true_bw if model_name==\"Breit‑Wigner\" else *true_gauss),\n",
    "             'k--', label='true model')\n",
    "    plt.plot(xs_fine, model_func(xs_fine, *popt),\n",
    "             'r-', label='curve_fit')\n",
    "    plt.plot(xs_fine, model_func(xs_fine, *xopt_gd),\n",
    "             'g-', label='gradient descent')\n",
    "    plt.plot(xs_fine, model_func(xs_fine, *res_bfgs.x),\n",
    "             'b-', label='minimize BFGS')\n",
    "    plt.plot(xs_fine, model_func(xs_fine, *res_nm.x),\n",
    "             'm-', label='minimize Nelder‑Mead')\n",
    "    plt.xlabel('x')\n",
    "    plt.ylabel('y')\n",
    "    plt.title(f\"Fit comparison: {model_name}\")\n",
    "    plt.legend()\n",
    "    plt.tight_layout()\n",
    "    plt.show()\n",
    "    \n",
    "    return {\n",
    "        'curve_fit': (popt, chi_cf),\n",
    "        'gradient_descent': (xopt_gd, chi_gd, len(hist)),\n",
    "        'minimize_BFGS': (res_bfgs.x, res_bfgs.fun, res_bfgs.nit, res_bfgs.nfev),\n",
    "        'minimize_NM': (res_nm.x, res_nm.fun, res_nm.nit, res_nm.nfev)\n",
    "    }\n",
    "\n",
    "# --- Run for both models ---\n",
    "initial_guess_bw = [4.0, 0.5, 9.0]\n",
    "res_bw = fit_and_compare(\"Breit‑Wigner\", breit_wigner,\n",
    "                        x_bw, y_bw, sigma_bw, initial_guess_bw)\n",
    "\n",
    "initial_guess_gauss = [4.0, 0.5, 9.0]\n",
    "res_gauss = fit_and_compare(\"Gaussian\", gaussian,\n",
    "                            x_gauss, y_gauss, sigma_gauss, initial_guess_gauss)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0f64dc91-74d0-43d3-891c-9f3100f3f448",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [conda env:base] *",
   "language": "python",
   "name": "conda-base-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
